{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea3b452-7b65-4aa6-a097-6fd5a57d0147",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "nltk.download('punkt') \n",
    "nltk.download('vader_lexicon') \n",
    "from textblob import TextBlob \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "from nltk.classify import NaiveBayesClassifier \n",
    "from nltk.corpus import subjectivity\n",
    "from nltk.sentiment import SentimentAnalyzer \n",
    "from nltk.sentiment.util import *\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer \n",
    "from nltk import tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a17c306-a54a-40d0-ad81-3d96203d1e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "PostMetric = pd.read_csv(\"FILE.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d057051-53da-492f-b2d2-8b98642d1b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_analysis_columns = ['negativity', 'neutrality', 'positivity', 'compound'] \n",
    "\n",
    "file_names = ['Whatever Dataset is called']\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()\n",
    "\n",
    "for i in range(len(file_names)):\n",
    "    expanded_text_dataset = []\n",
    "    file_name = file_names[i]\n",
    "    print('Sentiment analysis for: %s' %file_name)\n",
    "    df = pd.read_csv('%s.csv' % file_name)\n",
    "    column_names = list(PostMetric.columns.values)\n",
    "    all_columns = column_names + sentiment_analysis_columns\n",
    "    text_segment_list = list(df['Column with text needed for analysis'])\n",
    "    for j in range(len(text_segment_list)):\n",
    "        row_info = list(df.iloc[j])\n",
    "        text = text_segment_list[j]\n",
    "        try:\n",
    "            ss = sid.polarity_scores(text)\n",
    "            negativity = ss['neg']\n",
    "            neutrality = ss['neu']\n",
    "            positivity = ss['pos']\n",
    "            compound = ss['compound']\n",
    "            temp_data = row_info + [negativity, neutrality, positivity, compound]\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "        except:\n",
    "            print('Sentiment analysis not done: ' + str(j) + ' / ' + str(len(df)))\n",
    "            temp_data = row_info + ['NA', 'NA', 'NA', 'NA']\n",
    "            expanded_text_dataset.append(temp_data)\n",
    "    ##Storing the results in a dataset\n",
    "    df = pd.DataFrame(expanded_text_dataset, columns = all_columns)\n",
    "    df.to_excel('%s_sentiment_analysis.xlsx' %file_name)\n",
    "print(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
